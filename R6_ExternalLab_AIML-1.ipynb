{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels,num_classes=10)\n",
    "        \n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print('First 5 examples now are: ', train_labels[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [],
   "source": [
    "trainX=train_images\n",
    "trainY=train_labels\n",
    "testX=test_images\n",
    "testY=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59C_-IgOIVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 12.3277 - acc: 0.2204 - val_loss: 12.4029 - val_acc: 0.2260\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 12.3974 - acc: 0.2264 - val_loss: 11.9730 - val_acc: 0.2474\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 11.9311 - acc: 0.2498 - val_loss: 11.8669 - val_acc: 0.2626\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.8867 - acc: 0.2612 - val_loss: 11.7079 - val_acc: 0.2722\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.7206 - acc: 0.2712 - val_loss: 11.4734 - val_acc: 0.2849\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.5016 - acc: 0.2834 - val_loss: 11.3488 - val_acc: 0.2912\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.3391 - acc: 0.2920 - val_loss: 11.2312 - val_acc: 0.2981\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.2441 - acc: 0.2967 - val_loss: 11.2059 - val_acc: 0.3002\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.2033 - acc: 0.3004 - val_loss: 11.0740 - val_acc: 0.3082\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.0839 - acc: 0.3061 - val_loss: 11.0383 - val_acc: 0.3107\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 11.0326 - acc: 0.3107 - val_loss: 10.8935 - val_acc: 0.3187\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.8900 - acc: 0.3185 - val_loss: 10.8960 - val_acc: 0.3187\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.8805 - acc: 0.3203 - val_loss: 10.7315 - val_acc: 0.3300\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.7466 - acc: 0.3276 - val_loss: 10.9886 - val_acc: 0.3152\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.9961 - acc: 0.3148 - val_loss: 10.5346 - val_acc: 0.3416\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.5789 - acc: 0.3394 - val_loss: 10.5156 - val_acc: 0.3431\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.5118 - acc: 0.3436 - val_loss: 10.4860 - val_acc: 0.3453\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.5216 - acc: 0.3434 - val_loss: 10.4864 - val_acc: 0.3465\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.4866 - acc: 0.3453 - val_loss: 10.5104 - val_acc: 0.3449\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.5712 - acc: 0.3409 - val_loss: 10.4740 - val_acc: 0.3472\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.4639 - acc: 0.3468 - val_loss: 10.4965 - val_acc: 0.3454\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.5628 - acc: 0.3412 - val_loss: 10.3823 - val_acc: 0.3531\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.3771 - acc: 0.3522 - val_loss: 10.3627 - val_acc: 0.3532\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 10.4100 - acc: 0.3504 - val_loss: 10.4145 - val_acc: 0.3502\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.4015 - acc: 0.3500 - val_loss: 10.5466 - val_acc: 0.3427\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.6056 - acc: 0.3389 - val_loss: 10.2199 - val_acc: 0.3631\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 10.2308 - acc: 0.3605 - val_loss: 9.7010 - val_acc: 0.3913\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.7191 - acc: 0.3898 - val_loss: 11.9319 - val_acc: 0.2549\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 11.8986 - acc: 0.2562 - val_loss: 9.5415 - val_acc: 0.4018\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.5272 - acc: 0.4011 - val_loss: 11.2349 - val_acc: 0.2967\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 11.2457 - acc: 0.2962 - val_loss: 9.7199 - val_acc: 0.3918\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.7327 - acc: 0.3926 - val_loss: 8.9306 - val_acc: 0.4408\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 8.9273 - acc: 0.4418 - val_loss: 9.1475 - val_acc: 0.4271\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.1129 - acc: 0.4291 - val_loss: 9.6091 - val_acc: 0.3996\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.6066 - acc: 0.3999 - val_loss: 9.3625 - val_acc: 0.4152\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.3455 - acc: 0.4162 - val_loss: 9.0374 - val_acc: 0.4352\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.0063 - acc: 0.4364 - val_loss: 9.2380 - val_acc: 0.4216\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 9.1833 - acc: 0.4249 - val_loss: 9.3760 - val_acc: 0.4127\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.3702 - acc: 0.4125 - val_loss: 10.1630 - val_acc: 0.3640\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 10.1662 - acc: 0.3632 - val_loss: 9.4768 - val_acc: 0.4063\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.4341 - acc: 0.4082 - val_loss: 9.5415 - val_acc: 0.4043\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.5349 - acc: 0.4057 - val_loss: 9.0234 - val_acc: 0.4371\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.0119 - acc: 0.4377 - val_loss: 8.8797 - val_acc: 0.4454\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 8.8242 - acc: 0.4487 - val_loss: 9.0378 - val_acc: 0.4366\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 9.0203 - acc: 0.4377 - val_loss: 8.7520 - val_acc: 0.4543\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 8.7050 - acc: 0.4570 - val_loss: 8.7289 - val_acc: 0.4549\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 8.6906 - acc: 0.4576 - val_loss: 8.7332 - val_acc: 0.4551\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 8.7032 - acc: 0.4568 - val_loss: 8.9064 - val_acc: 0.4441\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 8.8547 - acc: 0.4464 - val_loss: 9.2413 - val_acc: 0.4241\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 9.2261 - acc: 0.4248 - val_loss: 8.8449 - val_acc: 0.4483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ccfdc71438>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=train_images\n",
    "trainY=train_labels\n",
    "testX=test_images\n",
    "testY=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 2.6315 - acc: 0.1593 - val_loss: 11.1229 - val_acc: 0.1550\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.4006 - acc: 0.1989 - val_loss: 9.4046 - val_acc: 0.1762\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2129 - acc: 0.2392 - val_loss: 8.0101 - val_acc: 0.2055\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.0586 - acc: 0.2774 - val_loss: 6.9076 - val_acc: 0.2360\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.9305 - acc: 0.3140 - val_loss: 6.0195 - val_acc: 0.2692\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.8232 - acc: 0.3486 - val_loss: 5.2817 - val_acc: 0.2988\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.7324 - acc: 0.3779 - val_loss: 4.6668 - val_acc: 0.3239\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.6551 - acc: 0.4056 - val_loss: 4.1615 - val_acc: 0.3451\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.5886 - acc: 0.4309 - val_loss: 3.7519 - val_acc: 0.3637\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.5308 - acc: 0.4540 - val_loss: 3.4203 - val_acc: 0.3808\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4802 - acc: 0.4729 - val_loss: 3.1489 - val_acc: 0.3928\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.4355 - acc: 0.4902 - val_loss: 2.9238 - val_acc: 0.4086\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.3957 - acc: 0.5070 - val_loss: 2.7348 - val_acc: 0.4220\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.3599 - acc: 0.5214 - val_loss: 2.5736 - val_acc: 0.4351\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.3276 - acc: 0.5345 - val_loss: 2.4352 - val_acc: 0.4475\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.2981 - acc: 0.5469 - val_loss: 2.3148 - val_acc: 0.4585\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.2712 - acc: 0.5572 - val_loss: 2.2095 - val_acc: 0.4686\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.2464 - acc: 0.5677 - val_loss: 2.1165 - val_acc: 0.4789\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.2235 - acc: 0.5775 - val_loss: 2.0338 - val_acc: 0.4884\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.2023 - acc: 0.5867 - val_loss: 1.9597 - val_acc: 0.4977\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.1825 - acc: 0.5951 - val_loss: 1.8931 - val_acc: 0.5077\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.1641 - acc: 0.6023 - val_loss: 1.8327 - val_acc: 0.5145\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.1468 - acc: 0.6086 - val_loss: 1.7776 - val_acc: 0.5229\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.1306 - acc: 0.6149 - val_loss: 1.7273 - val_acc: 0.5316\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.1153 - acc: 0.6207 - val_loss: 1.6810 - val_acc: 0.5416\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.1009 - acc: 0.6259 - val_loss: 1.6384 - val_acc: 0.5487\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.0873 - acc: 0.6309 - val_loss: 1.5989 - val_acc: 0.5555\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.0745 - acc: 0.6359 - val_loss: 1.5622 - val_acc: 0.5630\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.0623 - acc: 0.6406 - val_loss: 1.5281 - val_acc: 0.5718\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.0507 - acc: 0.6448 - val_loss: 1.4962 - val_acc: 0.5796\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.0396 - acc: 0.6489 - val_loss: 1.4664 - val_acc: 0.5847\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.0291 - acc: 0.6525 - val_loss: 1.4383 - val_acc: 0.5913\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.0190 - acc: 0.6563 - val_loss: 1.4119 - val_acc: 0.5971\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.0094 - acc: 0.6594 - val_loss: 1.3870 - val_acc: 0.6021\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.0002 - acc: 0.6626 - val_loss: 1.3635 - val_acc: 0.6081\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9914 - acc: 0.6655 - val_loss: 1.3413 - val_acc: 0.6129\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9830 - acc: 0.6683 - val_loss: 1.3202 - val_acc: 0.6167\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9749 - acc: 0.6713 - val_loss: 1.3001 - val_acc: 0.6200\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.9671 - acc: 0.6739 - val_loss: 1.2811 - val_acc: 0.6249\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9596 - acc: 0.6763 - val_loss: 1.2629 - val_acc: 0.6291\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9523 - acc: 0.6789 - val_loss: 1.2455 - val_acc: 0.6310\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9454 - acc: 0.6812 - val_loss: 1.2290 - val_acc: 0.6344\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.9387 - acc: 0.6838 - val_loss: 1.2131 - val_acc: 0.6372\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9322 - acc: 0.6863 - val_loss: 1.1979 - val_acc: 0.6403\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9260 - acc: 0.6886 - val_loss: 1.1834 - val_acc: 0.6423\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9199 - acc: 0.6905 - val_loss: 1.1694 - val_acc: 0.6459\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9141 - acc: 0.6923 - val_loss: 1.1559 - val_acc: 0.6493\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.9084 - acc: 0.6942 - val_loss: 1.1430 - val_acc: 0.6515\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.9029 - acc: 0.6962 - val_loss: 1.1305 - val_acc: 0.6539\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8976 - acc: 0.6982 - val_loss: 1.1185 - val_acc: 0.6554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cd08e61be0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.8925 - acc: 0.6999 - val_loss: 1.1069 - val_acc: 0.6573\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8875 - acc: 0.7016 - val_loss: 1.0958 - val_acc: 0.6589\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.8826 - acc: 0.7031 - val_loss: 1.0850 - val_acc: 0.6611\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8779 - acc: 0.7048 - val_loss: 1.0745 - val_acc: 0.6635\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.8733 - acc: 0.7063 - val_loss: 1.0644 - val_acc: 0.6648\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8688 - acc: 0.7076 - val_loss: 1.0546 - val_acc: 0.6674\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.8645 - acc: 0.7091 - val_loss: 1.0452 - val_acc: 0.6700\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8603 - acc: 0.7106 - val_loss: 1.0360 - val_acc: 0.6720\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8562 - acc: 0.7118 - val_loss: 1.0271 - val_acc: 0.6742\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.8522 - acc: 0.7131 - val_loss: 1.0185 - val_acc: 0.6764\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8483 - acc: 0.7142 - val_loss: 1.0102 - val_acc: 0.6773\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.8444 - acc: 0.7155 - val_loss: 1.0021 - val_acc: 0.6794\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8407 - acc: 0.7168 - val_loss: 0.9942 - val_acc: 0.6818\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.8371 - acc: 0.7178 - val_loss: 0.9865 - val_acc: 0.6832\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8336 - acc: 0.7189 - val_loss: 0.9791 - val_acc: 0.6853\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.8301 - acc: 0.7202 - val_loss: 0.9719 - val_acc: 0.6865\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8267 - acc: 0.7212 - val_loss: 0.9649 - val_acc: 0.6877\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.8234 - acc: 0.7224 - val_loss: 0.9581 - val_acc: 0.6901\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8202 - acc: 0.7234 - val_loss: 0.9515 - val_acc: 0.6914\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8170 - acc: 0.7244 - val_loss: 0.9450 - val_acc: 0.6931\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8140 - acc: 0.7254 - val_loss: 0.9387 - val_acc: 0.6940\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.8109 - acc: 0.7264 - val_loss: 0.9326 - val_acc: 0.6953\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8080 - acc: 0.7273 - val_loss: 0.9267 - val_acc: 0.6970\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.8051 - acc: 0.7283 - val_loss: 0.9209 - val_acc: 0.6987\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.8022 - acc: 0.7292 - val_loss: 0.9152 - val_acc: 0.7006\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7995 - acc: 0.7303 - val_loss: 0.9097 - val_acc: 0.7015\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7967 - acc: 0.7313 - val_loss: 0.9043 - val_acc: 0.7028\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7941 - acc: 0.7321 - val_loss: 0.8991 - val_acc: 0.7043\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7914 - acc: 0.7332 - val_loss: 0.8940 - val_acc: 0.7054\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7889 - acc: 0.7342 - val_loss: 0.8890 - val_acc: 0.7067\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7863 - acc: 0.7351 - val_loss: 0.8842 - val_acc: 0.7077\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7839 - acc: 0.7359 - val_loss: 0.8795 - val_acc: 0.7092\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7814 - acc: 0.7368 - val_loss: 0.8748 - val_acc: 0.7106\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7790 - acc: 0.7377 - val_loss: 0.8703 - val_acc: 0.7123\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7767 - acc: 0.7384 - val_loss: 0.8659 - val_acc: 0.7131\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.7744 - acc: 0.7392 - val_loss: 0.8616 - val_acc: 0.7142\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7721 - acc: 0.7399 - val_loss: 0.8574 - val_acc: 0.7156\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7699 - acc: 0.7407 - val_loss: 0.8533 - val_acc: 0.7172\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7677 - acc: 0.7415 - val_loss: 0.8493 - val_acc: 0.7185\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7656 - acc: 0.7422 - val_loss: 0.8454 - val_acc: 0.7192\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7635 - acc: 0.7429 - val_loss: 0.8415 - val_acc: 0.7202\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7614 - acc: 0.7434 - val_loss: 0.8378 - val_acc: 0.7213\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.7593 - acc: 0.7441 - val_loss: 0.8341 - val_acc: 0.7225\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7573 - acc: 0.7448 - val_loss: 0.8306 - val_acc: 0.7232\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.7554 - acc: 0.7455 - val_loss: 0.8271 - val_acc: 0.7234\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7534 - acc: 0.7462 - val_loss: 0.8236 - val_acc: 0.7241\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7515 - acc: 0.7468 - val_loss: 0.8203 - val_acc: 0.7254\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7496 - acc: 0.7475 - val_loss: 0.8170 - val_acc: 0.7258\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7477 - acc: 0.7479 - val_loss: 0.8138 - val_acc: 0.7266\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.7459 - acc: 0.7487 - val_loss: 0.8107 - val_acc: 0.7283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cd08f2df28>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "\n",
    "from keras.layers import Dense\n",
    "classifier = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "classifier.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Add Dense Layer which provides 100 Outputs after applying softmax\n",
    "classifier.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "\n",
    "## Adding the second hidden layer\n",
    "classifier.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "# Adding the output layer\n",
    "## Adding the second hidden layer\n",
    "classifier.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "classifier.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "sgd_optimizer2 = tf.keras.optimizers.SGD(lr=0.03)\n",
    "classifier.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2.2974 - acc: 0.1269 - val_loss: 2.2975 - val_acc: 0.1257\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2974 - acc: 0.1272 - val_loss: 2.2974 - val_acc: 0.1259\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2973 - acc: 0.1273 - val_loss: 2.2973 - val_acc: 0.1262\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2972 - acc: 0.1276 - val_loss: 2.2972 - val_acc: 0.1264\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 2.2971 - acc: 0.1278 - val_loss: 2.2971 - val_acc: 0.1265\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2970 - acc: 0.1279 - val_loss: 2.2971 - val_acc: 0.1267\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 2.2969 - acc: 0.1280 - val_loss: 2.2970 - val_acc: 0.1270\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2969 - acc: 0.1282 - val_loss: 2.2969 - val_acc: 0.1270\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2968 - acc: 0.1285 - val_loss: 2.2968 - val_acc: 0.1270\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2967 - acc: 0.1287 - val_loss: 2.2967 - val_acc: 0.1274\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2966 - acc: 0.1290 - val_loss: 2.2967 - val_acc: 0.1274\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2965 - acc: 0.1293 - val_loss: 2.2966 - val_acc: 0.1276\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2964 - acc: 0.1293 - val_loss: 2.2965 - val_acc: 0.1275\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2964 - acc: 0.1294 - val_loss: 2.2964 - val_acc: 0.1284\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2963 - acc: 0.1296 - val_loss: 2.2963 - val_acc: 0.1287\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2962 - acc: 0.1300 - val_loss: 2.2962 - val_acc: 0.1287\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2961 - acc: 0.1302 - val_loss: 2.2962 - val_acc: 0.1287\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2960 - acc: 0.1304 - val_loss: 2.2961 - val_acc: 0.1288\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2960 - acc: 0.1308 - val_loss: 2.2960 - val_acc: 0.1293\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2959 - acc: 0.1311 - val_loss: 2.2959 - val_acc: 0.1295\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2958 - acc: 0.1313 - val_loss: 2.2958 - val_acc: 0.1296\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 2.2957 - acc: 0.1316 - val_loss: 2.2958 - val_acc: 0.1298\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2956 - acc: 0.1318 - val_loss: 2.2957 - val_acc: 0.1299\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2956 - acc: 0.1319 - val_loss: 2.2956 - val_acc: 0.1300\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2955 - acc: 0.1320 - val_loss: 2.2955 - val_acc: 0.1305\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2954 - acc: 0.1323 - val_loss: 2.2955 - val_acc: 0.1308\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 2.2953 - acc: 0.1326 - val_loss: 2.2954 - val_acc: 0.1309\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2952 - acc: 0.1328 - val_loss: 2.2953 - val_acc: 0.1311\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2952 - acc: 0.1331 - val_loss: 2.2952 - val_acc: 0.1312\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2951 - acc: 0.1333 - val_loss: 2.2951 - val_acc: 0.1314\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2950 - acc: 0.1336 - val_loss: 2.2950 - val_acc: 0.1322\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 2.2949 - acc: 0.1336 - val_loss: 2.2950 - val_acc: 0.1322\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2948 - acc: 0.1339 - val_loss: 2.2949 - val_acc: 0.1327\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2948 - acc: 0.1342 - val_loss: 2.2948 - val_acc: 0.1332\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2947 - acc: 0.1344 - val_loss: 2.2947 - val_acc: 0.1334\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2946 - acc: 0.1346 - val_loss: 2.2946 - val_acc: 0.1338\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2945 - acc: 0.1349 - val_loss: 2.2946 - val_acc: 0.1343\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2944 - acc: 0.1353 - val_loss: 2.2945 - val_acc: 0.1347\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 2.2944 - acc: 0.1354 - val_loss: 2.2944 - val_acc: 0.1352\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2943 - acc: 0.1359 - val_loss: 2.2943 - val_acc: 0.1352\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2942 - acc: 0.1360 - val_loss: 2.2942 - val_acc: 0.1356\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 2.2941 - acc: 0.1363 - val_loss: 2.2942 - val_acc: 0.1355\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2940 - acc: 0.1366 - val_loss: 2.2941 - val_acc: 0.1357\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2940 - acc: 0.1368 - val_loss: 2.2940 - val_acc: 0.1359\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2939 - acc: 0.1371 - val_loss: 2.2939 - val_acc: 0.1361\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2938 - acc: 0.1375 - val_loss: 2.2939 - val_acc: 0.1365\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 2.2937 - acc: 0.1379 - val_loss: 2.2938 - val_acc: 0.1367\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2936 - acc: 0.1382 - val_loss: 2.2937 - val_acc: 0.1368\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.2936 - acc: 0.1385 - val_loss: 2.2936 - val_acc: 0.1372\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.2935 - acc: 0.1388 - val_loss: 2.2935 - val_acc: 0.1379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc789a5b38>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX=train_images\n",
    "trainY=train_labels\n",
    "testX=test_images\n",
    "testY=test_labels\n",
    "\n",
    "classifier.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classification_F-MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
