{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr75v_UYJjvs"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2sf67VoJjvx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zewyDcBlJjv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XycQGBSGJjv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[   0    1    2    3    4    5    6    7    8    9]\n",
      " [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgHSCXy3JjwA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okwo_SB5JjwI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# # normalize inputs from 0-255 to 0-1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPGVQ-JJJjwN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "print(x_train.shape)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DORCLgSwJjwV"
   },
   "outputs": [],
   "source": [
    "#Initialize model, reshape & normalize data\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden layers\n",
    "model.add(keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
    "model.add(keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "#Dropout layer\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "#Hidden layers\n",
    "model.add(keras.layers.Dense(60, activation='relu', name='Layer_3'))\n",
    "model.add(keras.layers.Dense(30, activation='relu', name='Layer_4'))\n",
    "\n",
    "#Dropout layer\n",
    "model.add(keras.layers.Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.7258 - acc: 0.7503 - val_loss: 0.4318 - val_acc: 0.8414\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.5170 - acc: 0.8255 - val_loss: 0.3808 - val_acc: 0.8644\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.4598 - acc: 0.8425 - val_loss: 0.3285 - val_acc: 0.8812\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.4290 - acc: 0.8542 - val_loss: 0.3226 - val_acc: 0.8806\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.4031 - acc: 0.8648 - val_loss: 0.3043 - val_acc: 0.8870\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3867 - acc: 0.8680 - val_loss: 0.2910 - val_acc: 0.8921\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.3714 - acc: 0.8736 - val_loss: 0.2749 - val_acc: 0.8992\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.3568 - acc: 0.8766 - val_loss: 0.2582 - val_acc: 0.9066\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3475 - acc: 0.8800 - val_loss: 0.2517 - val_acc: 0.9070\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3331 - acc: 0.8834 - val_loss: 0.2445 - val_acc: 0.9113\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3272 - acc: 0.8869 - val_loss: 0.2601 - val_acc: 0.9038\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.3194 - acc: 0.8894 - val_loss: 0.2305 - val_acc: 0.9132\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.3077 - acc: 0.8934 - val_loss: 0.2248 - val_acc: 0.9144\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.3037 - acc: 0.8955 - val_loss: 0.2308 - val_acc: 0.9183\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.2976 - acc: 0.8976 - val_loss: 0.2318 - val_acc: 0.9118\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.2912 - acc: 0.8990 - val_loss: 0.2250 - val_acc: 0.9177\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2853 - acc: 0.9009 - val_loss: 0.2074 - val_acc: 0.9244\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2816 - acc: 0.9025 - val_loss: 0.2036 - val_acc: 0.9235\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2784 - acc: 0.9032 - val_loss: 0.1968 - val_acc: 0.9267\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2741 - acc: 0.9061 - val_loss: 0.1960 - val_acc: 0.9285\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2671 - acc: 0.9064 - val_loss: 0.1928 - val_acc: 0.9290\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2627 - acc: 0.9073 - val_loss: 0.1885 - val_acc: 0.9306\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2541 - acc: 0.9102 - val_loss: 0.1854 - val_acc: 0.9313\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2576 - acc: 0.9104 - val_loss: 0.1818 - val_acc: 0.9326\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2503 - acc: 0.9115 - val_loss: 0.1749 - val_acc: 0.9342\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2515 - acc: 0.9130 - val_loss: 0.1714 - val_acc: 0.9364\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2470 - acc: 0.9136 - val_loss: 0.1709 - val_acc: 0.9362\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2417 - acc: 0.9164 - val_loss: 0.1696 - val_acc: 0.9351\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2377 - acc: 0.9167 - val_loss: 0.1681 - val_acc: 0.9376\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.2421 - acc: 0.9168 - val_loss: 0.1675 - val_acc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c939a8128>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,y_train,          \n",
    "          validation_data=(x_train,y_train),\n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2hAP94vJjwY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTA3bfEJjwa"
   },
   "source": [
    "### Now, to the above model, lets add Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6gX8n5SJjwb"
   },
   "source": [
    "### Import the ImageDataGenrator from keras and fit the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbz4uHBuJjwc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl-8dOo7Jjwf"
   },
   "source": [
    "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpI1_McYJjwg",
    "outputId": "6722631e-c925-448c-c780-93a3100249bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmPl5yE8Jjwm"
   },
   "source": [
    "### Run the above model using fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44ZnDdJYJjwn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwQQW5iOJjwq"
   },
   "source": [
    "###  Report the final train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1SrtBEPJjwq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBwVWNQC2qZD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KXqmUDW2rM1"
   },
   "source": [
    "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mja6OgQ3L18"
   },
   "source": [
    "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HzVTPUM3WZJ"
   },
   "source": [
    "### **Import neessary libraries for data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPM558TX4KMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6hicLwP4SqY"
   },
   "source": [
    "### **Load CIFAR10 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ1WzrXd4WNk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9Pht1ggHuiT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n28ccU6Hp6s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN3vYYhK4W0u"
   },
   "source": [
    "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJbekTKi4cmM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-SLtUhC4dK2"
   },
   "source": [
    "### **Prepare/fit the generator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSw8Bv2_4hb0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYyF-P8O4jQ8"
   },
   "source": [
    "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXug4z234mwQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
